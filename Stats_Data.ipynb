{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boolean-hamburg",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "korean-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import xlsxwriter\n",
    "import statistics as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-compromise",
   "metadata": {},
   "source": [
    "### Creating Excel Stats For Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "comparative-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeExcel(directory,fnames,mean,std_dev,we_avg):\n",
    "    path = 'C:\\\\Users\\\\tejas\\\\OneDrive\\\\Documents\\\\GitHub\\\\iitb\\\\excel_book_data'\n",
    "    os.chdir(\"{}\".format(path))\n",
    "    \n",
    "    workbook = xlsxwriter.Workbook('book_{}_data_stats.xlsx'.format(directory))\n",
    "    \n",
    "    worksheet = workbook.add_worksheet('{}'.format(directory))\n",
    "    \n",
    "    worksheet.write('A1', 'File_Names')\n",
    "    worksheet.write('B1', 'Mean')\n",
    "    worksheet.write('C1', 'Standard_Deviation')\n",
    "    worksheet.write('D1', 'Weighted_Average')\n",
    "    worksheet.set_column('A:A', 25)\n",
    "    worksheet.set_column('B:B', 25)\n",
    "    worksheet.set_column('C:C', 25)\n",
    "    worksheet.set_column('D:D', 25)\n",
    "        \n",
    "    \n",
    "    for i in range(len(fnames)):\n",
    "        if i == len(fnames):\n",
    "            worksheet.write('A{}'.format(i+2), fnames[i-1])\n",
    "        worksheet.write('A{}'.format(i+2),fnames[i])\n",
    "    \n",
    "    for i in range(len(mean)):\n",
    "        if i == len(mean):\n",
    "            worksheet.write('B{}'.format(i+2), mean[i-1])\n",
    "        worksheet.write('B{}'.format(i+2),mean[i])\n",
    "        \n",
    "    for i in range(len(std_dev)):\n",
    "        if i == len(std_dev):\n",
    "            worksheet.write('C{}'.format(i+2), std_dev[i-1])\n",
    "        worksheet.write('C{}'.format(i+2),std_dev[i])\n",
    "        \n",
    "    for i in range(len(we_avg)):\n",
    "        if i == len(we_avg):\n",
    "            worksheet.write('D{}'.format(i+2), we_avg[i-1])\n",
    "        worksheet.write('D{}'.format(i+2),we_avg[i])\n",
    "                \n",
    "    \n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-metadata",
   "metadata": {},
   "source": [
    "### Function For Generating Mean ,Standard Deviation & Weighted Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-crazy",
   "metadata": {},
   "source": [
    "###### Steps:\n",
    "1. Iterates each file.\n",
    "2. Iterates each line.\n",
    "3. Creates a list of words present in the file.\n",
    "4. Iterates through the list of words.\n",
    "5. Appends length of each word in a list named \"len_word\" .\n",
    "6. Calculates Mean and Standard Deviation for the above list.\n",
    "7. Calculates Weighted Average For Each Word Traversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "sitting-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateStatsData(directory,fnames):\n",
    "    mean = []\n",
    "    std_dev = []\n",
    "    we_avg = []\n",
    "    for i in range(len(fnames)):\n",
    "#         print(fnames[i]) - checkpoint\n",
    "        with open(fnames[i], 'r' , encoding=\"utf8\") as f:\n",
    "            len_word = []\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                if len(words) == 0:\n",
    "                    continue\n",
    "                words.pop(0)\n",
    "                for word in words:\n",
    "                    len_word.append(len(word))\n",
    "                    \n",
    "            # Calculating Mean\n",
    "            mean.append(round(st.mean(len_word),2))\n",
    "            \n",
    "            # Calculating Standard Deviation\n",
    "            std_dev.append(round(st.stdev(len_word),2))\n",
    "            \n",
    "            # Segregating values and their weights\n",
    "            len_word.sort()\n",
    "            df = pd.DataFrame([[x,len_word.count(x)] for x in set(len_word)], columns = ['values','weights'])\n",
    "            \n",
    "            # Calculating Weighted Average\n",
    "            we_avg.append(round(np.average(df['values'], weights=df['weights']),2))\n",
    "    \n",
    "    \n",
    "    writeExcel(directory,fnames,mean,std_dev,we_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-universal",
   "metadata": {},
   "source": [
    "### Fetching Data From Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "isolated-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.72it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\tejas\\\\OneDrive\\\\Documents\\\\GitHub\\\\iitb'\n",
    "if path != 'C:\\\\Users\\\\tejas\\\\OneDrive\\\\Documents\\\\GitHub\\\\iitb\\\\book_data':\n",
    "    os.chdir(\"{}\\\\book_data\".format(path))\n",
    "    path = os.getcwd()\n",
    "data = os.walk('.')\n",
    "dnames = []\n",
    "for root, directories, files in data:\n",
    "    for i in tqdm(range(len(directories))):\n",
    "        for directory in directories:\n",
    "            fnames = []\n",
    "    #         print(directory) - checkpoint\n",
    "            dnames.append(directory)\n",
    "            os.chdir(\"{}\\\\{}\".format(path,directory))\n",
    "            data = os.walk('.')\n",
    "            for root, directories, files in data:\n",
    "                for file in glob.glob(\"*.txt\"):\n",
    "                    fnames.append(file)\n",
    "    #         print(fnames) -- checkpoint\n",
    "            calculateStatsData(directory,fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-remark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
